{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e3732ea",
   "metadata": {},
   "source": [
    "## Tutorial: Index mixed content using image verbalizations and the Document Extraction skill\n",
    "\n",
    "- Image Verbalization\n",
    "\n",
    "- Azure OpenAI describes image - so it can be retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import os\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91267db",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True) # take environment variables from .env.\n",
    "\n",
    "def check_empty(variable_name, value):  \n",
    "    if not value:  \n",
    "        print(f\"{variable_name} is empty.\")  \n",
    "  \n",
    "AZURE_SEARCH_SERVICE_NAME = os.getenv(\"AZURE_SEARCH_SERVICE_NAME\")\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "\n",
    "\n",
    "AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB = os.getenv(\"AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB\")\n",
    "\n",
    "AZURE_SEARCH_API_KEY = os.getenv(\"AZURE_SEARCH_API_KEY\")\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "BLOB_CONTAINER_NAME = os.getenv(\"BLOB_CONTAINER_NAME\") \n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_EMBEDDING_MODEL_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_DIMENSIONS = os.getenv(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\")\n",
    "AZURE_OPENAI_CHATCOMPLETIONS_ENDPOINT = os.getenv(\"AZURE_OPENAI_CHATCOMPLETIONS_ENDPOINT\")\n",
    "AZURE_AI_SERVICES_ENDPOINT = os.getenv(\"AZURE_AI_SERVICES_ENDPOINT\")\n",
    "AZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "AZURE_AI_SERVICES_ENDPOINT = os.getenv(\"AZURE_AI_SERVICES_ENDPOINT\")\n",
    "AZURE_AI_SERVICES_API_KEY = os.getenv(\"AZURE_AI_SERVICES_API_KEY\")\n",
    "\n",
    "check_empty(\"AZURE_SEARCH_SERVICE_NAME\", AZURE_SEARCH_SERVICE_NAME)\n",
    "check_empty(\"AZURE_SEARCH_API_KEY\", AZURE_SEARCH_API_KEY)\n",
    "check_empty(\"BLOB_CONNECTION_STRING\", BLOB_CONNECTION_STRING)\n",
    "check_empty(\"BLOB_CONTAINER_NAME\", BLOB_CONTAINER_NAME)\n",
    "check_empty(\"AZURE_OPENAI_ENDPOINT\", AZURE_OPENAI_ENDPOINT)\n",
    "check_empty(\"AZURE_OPENAI_EMBEDDING_MODEL_NAME\", AZURE_OPENAI_EMBEDDING_MODEL_NAME)\n",
    "check_empty(\"AZURE_OPENAI_EMBEDDING_DIMENSIONS\", AZURE_OPENAI_EMBEDDING_DIMENSIONS)\n",
    "check_empty(\"AZURE_AI_SERVICES_ENDPOINT\", AZURE_AI_SERVICES_ENDPOINT)\n",
    "check_empty(\"AZURE_OPENAI_KEY\", AZURE_OPENAI_KEY)\n",
    "check_empty(\"AZURE_OPENAI_CHATCOMPLETIONS_ENDPOINT\", AZURE_OPENAI_CHATCOMPLETIONS_ENDPOINT)\n",
    "check_empty(\"AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB\", AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB)\n",
    "check_empty(\"AZURE_AI_SERVICES_ENDPOINT\", AZURE_AI_SERVICES_ENDPOINT)\n",
    "check_empty(\"AZURE_AI_SERVICES_API_KEY\", AZURE_AI_SERVICES_API_KEY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f47bbe",
   "metadata": {},
   "source": [
    "## Create the Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ead36",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLOB_CONTAINER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e281503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your actual base URL and API key\n",
    "\n",
    "azure_search_api_key = AZURE_SEARCH_API_KEY\n",
    "base_url = AZURE_SEARCH_SERVICE_ENDPOINT\n",
    "index_name = AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB\n",
    "index = AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB\n",
    "\n",
    "url = '{0}/datasources/{1}-datasource?api-version=2025-05-01-preview'.format(base_url, index_name)\n",
    "print(url)\n",
    "\n",
    "payload = json.dumps(  \n",
    "    {\n",
    "    \"description\": None,\n",
    "    \"type\": \"azureblob\",\n",
    "    \"subtype\": None,\n",
    "    \"credentials\": {\n",
    "      \"connectionString\": BLOB_CONNECTION_STRING\n",
    "    },\n",
    "    \"container\": {\n",
    "      \"name\": BLOB_CONTAINER_NAME,\n",
    "      \"query\": None\n",
    "    },\n",
    "    \"dataChangeDetectionPolicy\": None,\n",
    "    \"dataDeletionDetectionPolicy\": None,\n",
    "    \"encryptionKey\": None,\n",
    "    \"identity\": None\n",
    "  }\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    'api-key': azure_search_api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70004f19",
   "metadata": {},
   "source": [
    "## Create the index - the Vectorizer here is actually OpenAI - not Azure AI Multimodal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842949ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your actual values\n",
    "vectorizer = \"my-vectorizer\"\n",
    "openAIResourceUri = AZURE_OPENAI_ENDPOINT\n",
    "openAIKey = AZURE_OPENAI_KEY\n",
    "\n",
    "url = '{0}/indexes/{1}/?api-version=2025-05-01-preview'.format(base_url, index_name)\n",
    "\n",
    "payload = json.dumps(\n",
    "    {\n",
    "    \"fields\": [\n",
    "        {\n",
    "            \"name\": \"content_id\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"retrievable\": True,\n",
    "            \"key\": True,\n",
    "            \"analyzer\": \"keyword\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"text_document_id\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": False,\n",
    "            \"filterable\": True,\n",
    "            \"retrievable\": True,\n",
    "            \"stored\": True,\n",
    "            \"sortable\": False,\n",
    "            \"facetable\": False\n",
    "        },          \n",
    "        {\n",
    "            \"name\": \"document_title\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"image_document_id\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"filterable\": True,\n",
    "            \"retrievable\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content_text\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": True,\n",
    "            \"retrievable\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content_embedding\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"dimensions\": 3072,\n",
    "            \"searchable\": True,\n",
    "            \"retrievable\": True,\n",
    "            \"vectorSearchProfile\": \"hnsw\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"content_path\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": False,\n",
    "            \"retrievable\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"offset\",\n",
    "            \"type\": \"Edm.String\",\n",
    "            \"searchable\": False,\n",
    "            \"retrievable\": True\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"location_metadata\",\n",
    "            \"type\": \"Edm.ComplexType\",\n",
    "            \"fields\": [\n",
    "                {\n",
    "                \"name\": \"page_number\",\n",
    "                \"type\": \"Edm.Int32\",\n",
    "                \"searchable\": False,\n",
    "                \"retrievable\": True\n",
    "                },\n",
    "                {\n",
    "                \"name\": \"bounding_polygons\",\n",
    "                \"type\": \"Edm.String\",\n",
    "                \"searchable\": False,\n",
    "                \"retrievable\": True,\n",
    "                \"filterable\": False,\n",
    "                \"sortable\": False,\n",
    "                \"facetable\": False\n",
    "                }\n",
    "            ]\n",
    "        }         \n",
    "    ],\n",
    "    \"vectorSearch\": {\n",
    "        \"profiles\": [\n",
    "            {\n",
    "                \"name\": \"hnsw\",\n",
    "                \"algorithm\": \"defaulthnsw\",\n",
    "                \"vectorizer\": vectorizer\n",
    "            }\n",
    "        ],\n",
    "        \"algorithms\": [\n",
    "            {\n",
    "                \"name\": \"defaulthnsw\",\n",
    "                \"kind\": \"hnsw\",\n",
    "                \"hnswParameters\": {\n",
    "                    \"m\": 4,\n",
    "                    \"efConstruction\": 400,\n",
    "                    \"metric\": \"cosine\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "         \"vectorizers\": [\n",
    "            {\n",
    "              \"name\": vectorizer,\n",
    "              \"kind\": \"azureOpenAI\",    \n",
    "              \"azureOpenAIParameters\": {\n",
    "                \"resourceUri\": openAIResourceUri,\n",
    "                \"deploymentId\": \"text-embedding-3-large\",\n",
    "                \"apiKey\": openAIKey,\n",
    "                \"modelName\": \"text-embedding-3-large\"\n",
    "              }\n",
    "            }\n",
    "        ]     \n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"defaultConfiguration\": \"semanticconfig\",\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"semanticconfig\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"document_title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    'api-key': azure_search_api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a87428",
   "metadata": {},
   "source": [
    "## Skillset\n",
    "\n",
    "TODO: Add back in datauri if data doesnt land in blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ef901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "imageProjectionContainer = \"imageprojection2\"\n",
    "storageConnectionString = BLOB_CONNECTION_STRING\n",
    "chatcompletionsuri = AZURE_OPENAI_CHATCOMPLETIONS_ENDPOINT\n",
    "\n",
    "\n",
    "url = '{0}/skillsets/{1}-skillset?api-version=2025-05-01-preview'.format(base_url, index_name)\n",
    "\n",
    "payload = json.dumps(\n",
    "{\n",
    "  \"description\": \"A test skillset\",\n",
    "  \"skills\": [\n",
    "    {\n",
    "      \"@odata.type\": \"#Microsoft.Skills.Util.DocumentExtractionSkill\",\n",
    "      \"name\": \"document-extraction-skill\",\n",
    "      \"description\": \"Document extraction skill to exract text and images from documents\",\n",
    "      \"parsingMode\": \"default\",\n",
    "      \"dataToExtract\": \"contentAndMetadata\",\n",
    "      \"configuration\": {\n",
    "          \"imageAction\": \"generateNormalizedImages\",\n",
    "          \"normalizedImageMaxWidth\": 2000,\n",
    "          \"normalizedImageMaxHeight\": 2000\n",
    "      },\n",
    "      \"context\": \"/document\",\n",
    "      \"inputs\": [\n",
    "        {\n",
    "          \"name\": \"file_data\",\n",
    "          \"source\": \"/document/file_data\"\n",
    "        }\n",
    "      ],\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"name\": \"content\",\n",
    "          \"targetName\": \"extracted_content\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"normalized_images\",\n",
    "          \"targetName\": \"normalized_images\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"@odata.type\": \"#Microsoft.Skills.Text.SplitSkill\",\n",
    "      \"name\": \"split-skill\",\n",
    "      \"description\": \"Split skill to chunk documents\",\n",
    "      \"context\": \"/document\",\n",
    "      \"defaultLanguageCode\": \"en\",\n",
    "      \"textSplitMode\": \"pages\",\n",
    "      \"maximumPageLength\": 2000,\n",
    "      \"pageOverlapLength\": 200,\n",
    "      \"unit\": \"characters\",\n",
    "      \"inputs\": [\n",
    "        {\n",
    "          \"name\": \"text\",\n",
    "          \"source\": \"/document/extracted_content\",\n",
    "          \"inputs\": []\n",
    "        }\n",
    "      ],\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"name\": \"textItems\",\n",
    "          \"targetName\": \"pages\"\n",
    "        }\n",
    "      ]\n",
    "    }, \n",
    "    {\n",
    "    \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
    "    \"name\": \"text-embedding-skill\",\n",
    "    \"description\": \"Embedding skill for text\",\n",
    "    \"context\": \"/document/pages/*\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "        \"name\": \"text\",\n",
    "        \"source\": \"/document/pages/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "        \"name\": \"embedding\",\n",
    "        \"targetName\": \"text_vector\"\n",
    "        }\n",
    "    ],\n",
    "    \"resourceUri\": openAIResourceUri,\n",
    "    \"deploymentId\": \"text-embedding-3-large\",\n",
    "    \"apiKey\": openAIKey,\n",
    "    \"dimensions\": 3072,\n",
    "    \"modelName\": \"text-embedding-3-large\"\n",
    "    },\n",
    "    {\n",
    "    \"@odata.type\": \"#Microsoft.Skills.Custom.ChatCompletionSkill\",\n",
    "    \"name\": \"genAI-prompt-skill\",\n",
    "    \"description\": \"GenAI Prompt skill for image verbalization\",\n",
    "    \"uri\": chatcompletionsuri,\n",
    "    \"timeout\": \"PT1M\",\n",
    "    \"apiKey\": openAIKey,\n",
    "    \"context\": \"/document/normalized_images/*\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "        \"name\": \"systemMessage\",\n",
    "        \"source\": \"='You are tasked with generating concise, accurate descriptions of images, figures, diagrams, or charts in documents. The goal is to capture the key information and meaning conveyed by the image without including extraneous details like style, colors, visual aesthetics, or size.\\n\\nInstructions:\\nContent Focus: Describe the core content and relationships depicted in the image.\\n\\nFor diagrams, specify the main elements and how they are connected or interact.\\nFor charts, highlight key data points, trends, comparisons, or conclusions.\\nFor figures or technical illustrations, identify the components and their significance.\\nClarity & Precision: Use concise language to ensure clarity and technical accuracy. Avoid subjective or interpretive statements.\\n\\nAvoid Visual Descriptors: Exclude details about:\\n\\nColors, shading, and visual styles.\\nImage size, layout, or decorative elements.\\nFonts, borders, and stylistic embellishments.\\nContext: If relevant, relate the image to the broader content of the technical document or the topic it supports.\\n\\nExample Descriptions:\\nDiagram: \\\"A flowchart showing the four stages of a machine learning pipeline: data collection, preprocessing, model training, and evaluation, with arrows indicating the sequential flow of tasks.\\\"\\n\\nChart: \\\"A bar chart comparing the performance of four algorithms on three datasets, showing that Algorithm A consistently outperforms the others on Dataset 1.\\\"\\n\\nFigure: \\\"A labeled diagram illustrating the components of a transformer model, including the encoder, decoder, self-attention mechanism, and feedforward layers.\\\"'\"\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"userMessage\",\n",
    "        \"source\": \"='Please describe this image.'\"\n",
    "        },\n",
    "        {\n",
    "        \"name\": \"image\",\n",
    "        \"source\": \"/document/normalized_images/*/data\"\n",
    "        }\n",
    "        ],\n",
    "        \"outputs\": [\n",
    "            {\n",
    "            \"name\": \"response\",\n",
    "            \"targetName\": \"verbalizedImage\"\n",
    "            }\n",
    "        ]\n",
    "    },    \n",
    "    {\n",
    "    \"@odata.type\": \"#Microsoft.Skills.Text.AzureOpenAIEmbeddingSkill\",\n",
    "    \"name\": \"verblized-image-embedding-skill\",\n",
    "    \"description\": \"Embedding skill for verbalized images\",\n",
    "    \"context\": \"/document/normalized_images/*\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "        \"name\": \"text\",\n",
    "        \"source\": \"/document/normalized_images/*/verbalizedImage\",\n",
    "        \"inputs\": []\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "        \"name\": \"embedding\",\n",
    "        \"targetName\": \"verbalizedImage_vector\"\n",
    "        }\n",
    "    ],\n",
    "    \"resourceUri\": openAIResourceUri,\n",
    "    \"deploymentId\": \"text-embedding-3-large\",\n",
    "    \"apiKey\": openAIKey,\n",
    "    \"dimensions\": 3072,\n",
    "    \"modelName\": \"text-embedding-3-large\"\n",
    "    },\n",
    "    {\n",
    "      \"@odata.type\": \"#Microsoft.Skills.Util.ShaperSkill\",\n",
    "      \"name\": \"shaper-skill\",\n",
    "      \"description\": \"Shaper skill to reshape the data to fit the index schema\",\n",
    "      \"context\": \"/document/normalized_images/*\",\n",
    "      \"inputs\": [\n",
    "        {\n",
    "          \"name\": \"normalized_images\",\n",
    "          \"source\": \"/document/normalized_images/*\",\n",
    "          \"inputs\": []\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"imagePath\",\n",
    "          \"source\": \"='{imageProjectionContainer}/'+$(/document/normalized_images/*/imagePath)\".format(imageProjectionContainer=imageProjectionContainer),\n",
    "          \"inputs\": []\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"location_metadata\",\n",
    "          \"sourceContext\": \"/document/normalized_images/*\",\n",
    "          \"inputs\": [\n",
    "            {\n",
    "              \"name\": \"page_number\",\n",
    "              \"source\": \"/document/normalized_images/*/pageNumber\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"bounding_polygons\",\n",
    "              \"source\": \"/document/normalized_images/*/boundingPolygon\"\n",
    "            }              \n",
    "          ]\n",
    "        }        \n",
    "      ],\n",
    "      \"outputs\": [\n",
    "        {\n",
    "          \"name\": \"output\",\n",
    "          \"targetName\": \"new_normalized_images\"\n",
    "        }\n",
    "      ]\n",
    "    }      \n",
    "  ], \n",
    "   \"indexProjections\": {\n",
    "      \"selectors\": [\n",
    "        {\n",
    "          \"targetIndexName\": index,\n",
    "          \"parentKeyFieldName\": \"text_document_id\",\n",
    "          \"sourceContext\": \"/document/pages/*\",\n",
    "          \"mappings\": [    \n",
    "            {\n",
    "            \"name\": \"content_embedding\",\n",
    "            \"source\": \"/document/pages/*/text_vector\"\n",
    "            },                      \n",
    "            {\n",
    "              \"name\": \"content_text\",\n",
    "              \"source\": \"/document/pages/*\"\n",
    "            },             \n",
    "            {\n",
    "              \"name\": \"document_title\",\n",
    "              \"source\": \"/document/document_title\"\n",
    "            }   \n",
    "          ]\n",
    "        },        \n",
    "        {\n",
    "          \"targetIndexName\": index,\n",
    "          \"parentKeyFieldName\": \"image_document_id\",\n",
    "          \"sourceContext\": \"/document/normalized_images/*\",\n",
    "          \"mappings\": [    \n",
    "            {\n",
    "            \"name\": \"content_text\",\n",
    "            \"source\": \"/document/normalized_images/*/verbalizedImage\"\n",
    "            },  \n",
    "            {\n",
    "            \"name\": \"content_embedding\",\n",
    "            \"source\": \"/document/normalized_images/*/verbalizedImage_vector\"\n",
    "            },                                           \n",
    "            {\n",
    "              \"name\": \"content_path\",\n",
    "              \"source\": \"/document/normalized_images/*/new_normalized_images/imagePath\"\n",
    "            },                    \n",
    "            {\n",
    "              \"name\": \"document_title\",\n",
    "              \"source\": \"/document/document_title\"\n",
    "            },\n",
    "            {\n",
    "              \"name\": \"location_metadata\",\n",
    "              \"source\": \"/document/normalized_images/*/new_normalized_images/location_metadata\"\n",
    "            }            \n",
    "          ]\n",
    "        }\n",
    "      ],\n",
    "      \"parameters\": {\n",
    "        \"projectionMode\": \"skipIndexingParentDocuments\"\n",
    "      }\n",
    "  },  \n",
    "  \"knowledgeStore\": {\n",
    "    \"storageConnectionString\": storageConnectionString,\n",
    "    \"projections\": [\n",
    "      {\n",
    "        \"files\": [\n",
    "          {\n",
    "            \"storageContainer\": imageProjectionContainer,\n",
    "            \"source\": \"/document/normalized_images/*\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    'api-key': azure_search_api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "url = '{0}/indexers/{1}-indexer/?api-version=2025-05-01-preview'.format(base_url, index_name)\n",
    "print(url)\n",
    "\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"dataSourceName\": \"{0}-datasource\".format(index_name),\n",
    "  \"skillsetName\": \"{0}-skillset\".format(index_name),\n",
    "  \"targetIndexName\": \"{0}\".format(index_name),\n",
    "  \"parameters\": {\n",
    "    \"maxFailedItems\": -1,\n",
    "    \"maxFailedItemsPerBatch\": 0,\n",
    "    \"batchSize\": 1,\n",
    "    \"configuration\": {\n",
    "      \"allowSkillsetToReadFileData\": True\n",
    "    }\n",
    "  },\n",
    "  \"fieldMappings\": [\n",
    "    {\n",
    "      \"sourceFieldName\": \"metadata_storage_name\",\n",
    "      \"targetFieldName\": \"document_title\"\n",
    "    }\n",
    "  ],\n",
    "  \"outputFieldMappings\": []\n",
    "}\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    'api-key': azure_search_api_key,\n",
    "    'Content-Type': 'application/json'\n",
    "    }\n",
    "\n",
    "response = requests.request(\"PUT\", url, headers=headers, data=payload)\n",
    "\n",
    "print(\"Status Code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb90255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import VectorizableTextQuery\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "# Pure Vector Search\n",
    "query = \"what does the filament winding process scheme look like\"\n",
    "query = \"What does compound (BDMA) structure look like\"\n",
    "endpoint = AZURE_SEARCH_SERVICE_ENDPOINT\n",
    "index_name = AZURE_SEARCH_INDEX_DOC_EXTRACT_IMAGE_VERB\n",
    "print(f\"Using index: {index_name}\")\n",
    "\n",
    "search_client = SearchClient(endpoint, index_name, credential=credential)\n",
    "vector_query = VectorizableTextQuery(text=query, k_nearest_neighbors=5, fields=\"content_embedding\", exhaustive=True)\n",
    "# Use the below query to pass in the raw vector query instead of the query vectorization\n",
    "# vector_query = RawVectorQuery(vector=generate_embeddings(query), k_nearest_neighbors=3, fields=\"vector\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vector_queries= [vector_query],\n",
    "    top=5\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print('------')\n",
    "    print(result['content_text'])\n",
    "    print(\"image id = \" + str(result['image_document_id']) if result['image_document_id'] is not None else \"image_document_id is missing\") \n",
    "    print(\"content id = \" + str(result['content_id']) if result['content_id'] is not None else \"content id is missing\") \n",
    "    print(\"path = \" + str(result['content_path']) if result['content_path'] is not None else \"path is missing\") \n",
    "    # print(f\"parent_id: {result['parent_id']}\")  \n",
    "    # print(f\"chunk_id: {result['chunk_id']}\")  \n",
    "    # print(f\"page_number: {result['page_number']}\")\n",
    "    # print(f\"Score: {result['@search.score']}\")  \n",
    "    # print(f\"Content: {result['chunk']}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac0d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
